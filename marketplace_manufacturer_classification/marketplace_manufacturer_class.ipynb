{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f47633fc",
   "metadata": {},
   "source": [
    "# Классификация текста с помощью трансформера BERT\n",
    "\n",
    "Оригинальная идея подчерпнута отсюда https://www.kaggle.com/c/learn-ai-bbc и отсюда https://habr.com/ru/post/655517/\n",
    "\n",
    "\n",
    "### Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06742b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "device = torch.device('cuda')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb5820b",
   "metadata": {},
   "source": [
    "### Чтение нашего датасета, состоящего из html и лейблов в txt файле\n",
    "\n",
    "В файле две строки\n",
    "\n",
    "Первая:\n",
    " - Label 0 - Маркет\n",
    " - Label 1 - Сайт\n",
    " - Label 2 - Мусор\n",
    "\n",
    "\n",
    "Вторая: \n",
    " - Label 0 - Производитель\n",
    " - Label 1 - Перекуп\n",
    "\n",
    "Сейчас работаем по **первой**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b220064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>найти Ваши предложения +7 (495) 211-75-55 info...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Шплинт, шайба пружинная, гровет, шайба стопорн...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Двигатель Cummins в сборе +86-17623022502 loui...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Дизельные электростанции (генераторы) — купить...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Запчасти для китайских автомобилей, грузовиков...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Купить дизельную электростанцию в России Перей...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Доставка и оплата от ООО ГК \"Техмаш\" Войти Ваш...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Купить гайки в Санкт-Петербурге (СПб) ЛЗСК ГОС...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>купить вакуум interpuls, Ваш город: Определени...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Гайки круглые со шлицем на торце ГОСТ 10657-80...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ГайкиПродажа металлопроката оптом и в розницу ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Дизельные генераторы 10 кВт купить в Москве в ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Вакуумные шланги ОБРАТНАЯ СВЯЗЬ КОНТАКТНОЕ ЛИЦ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Дизельные генераторы и электростанции купить в...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Рукава Торговый дом РТИ (Санкт-Петербург) ПОЧТ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Рукава и шланги промышленные ТЕХПРОМ Производс...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>дизельные генераторы купить —  купить по низко...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Крепеж колес — belais ✔️ поиск Карта Краснодар...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Купить рукав и шланг ГОСТ в Москве недорого – ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Изготовление деталей на автоматах продольного ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>гайка шестигранная DIN934 М6 40 шткупить по вы...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Бензиновые генераторы купить в Москве и России...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  target\n",
       "0   найти Ваши предложения +7 (495) 211-75-55 info...       1\n",
       "1   Шплинт, шайба пружинная, гровет, шайба стопорн...       1\n",
       "2   Двигатель Cummins в сборе +86-17623022502 loui...       1\n",
       "3   Дизельные электростанции (генераторы) — купить...       0\n",
       "4   Запчасти для китайских автомобилей, грузовиков...       0\n",
       "5   Купить дизельную электростанцию в России Перей...       1\n",
       "6   Доставка и оплата от ООО ГК \"Техмаш\" Войти Ваш...       0\n",
       "7   Купить гайки в Санкт-Петербурге (СПб) ЛЗСК ГОС...       0\n",
       "8   купить вакуум interpuls, Ваш город: Определени...       0\n",
       "9   Гайки круглые со шлицем на торце ГОСТ 10657-80...       1\n",
       "10  ГайкиПродажа металлопроката оптом и в розницу ...       1\n",
       "11  Дизельные генераторы 10 кВт купить в Москве в ...       1\n",
       "12  Вакуумные шланги ОБРАТНАЯ СВЯЗЬ КОНТАКТНОЕ ЛИЦ...       1\n",
       "13  Дизельные генераторы и электростанции купить в...       0\n",
       "14  Рукава Торговый дом РТИ (Санкт-Петербург) ПОЧТ...       1\n",
       "15  Рукава и шланги промышленные ТЕХПРОМ Производс...       1\n",
       "16  дизельные генераторы купить —  купить по низко...       0\n",
       "17  Крепеж колес — belais ✔️ поиск Карта Краснодар...       0\n",
       "18  Купить рукав и шланг ГОСТ в Москве недорого – ...       0\n",
       "19  Изготовление деталей на автоматах продольного ...       1\n",
       "20  гайка шестигранная DIN934 М6 40 шткупить по вы...       0\n",
       "21  Бензиновые генераторы купить в Москве и России...       0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "indir = 'dataset'\n",
    "indir = os.path.abspath(indir)\n",
    "\n",
    "sites = [x for x in os.listdir(indir) if x.endswith('.txt')]\n",
    "\n",
    "pairs = []\n",
    "\n",
    "for pair in sites:\n",
    "    site = os.path.splitext(pair)[0] + '.html'\n",
    "    \n",
    "\n",
    "    with open(os.path.join(indir, site)) as f:\n",
    "        lines = f.read().rstrip().replace(' - ','').replace(' | ', '')\n",
    "        clean_text = ' '.join(BeautifulSoup(lines, \"html.parser\").stripped_strings)\n",
    "        \n",
    "    with open(os.path.join(indir, pair)) as f:\n",
    "        lines = f.readlines()\n",
    "        label = int(lines[0])\n",
    "        \n",
    "    pairs.append([clean_text, label])\n",
    "\n",
    "#print(pairs)\n",
    "\n",
    "df = pd.DataFrame(pairs, columns = ['text', 'target'])\n",
    "\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b001818",
   "metadata": {},
   "source": [
    "Загрузка претренированной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25da68b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = AutoModel.from_pretrained(\"DeepPavlov/rubert-base-cased-sentence\")\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased-sentence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f126d232",
   "metadata": {},
   "source": [
    "Разбиение выборок на текст и таргет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e573f3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text'].astype('str')\n",
    "y = df['target'].astype(int)\n",
    "\n",
    "X_train, y_train = X,y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5848b985",
   "metadata": {},
   "source": [
    "График длин текстов. Он поможет определить оптимальную длину последовательности токенов, чтобы избежать разреженных векторов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bc02af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_len = [len(str(i).split()) for i in X_train]\n",
    "pd.Series(seq_len).hist(bins = 100, range =(0,5000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3451e756",
   "metadata": {},
   "source": [
    "Токенизация текста\n",
    "Берем длину 500 (эта реализация BERT не дает сделать больше 512 к сожалению)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac86846d",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_len = 500\n",
    "\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    X_train.values,\n",
    "    max_length = token_len,\n",
    "    padding = 'max_length',\n",
    "    truncation = True\n",
    ")\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    X_test.values,\n",
    "    max_length = token_len,\n",
    "    padding = 'max_length',\n",
    "    truncation = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73fdcb2",
   "metadata": {},
   "source": [
    "Создание датасета для обучения из токенов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "630cc425",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "\n",
    "\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(y_train.values)\n",
    "\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(y_test.values)\n",
    "\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler = train_sampler, batch_size = batch_size)\n",
    "\n",
    "test_data =  TensorDataset(test_seq, test_mask, test_y)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler = test_sampler, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1204e008",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(test_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb13d99",
   "metadata": {},
   "source": [
    "Вместо обучения всего BERT добавим слой для классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b1433b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in bert.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "class BERT_Arch(nn.Module):\n",
    "    \n",
    "    def __init__(self, bert):\n",
    "        super(BERT_Arch, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(768,512)\n",
    "        self.fc2 = nn.Linear(512,2)\n",
    "        self.softmax = nn.LogSoftmax(dim = 1)\n",
    "    \n",
    "    def forward(self, sent_id, mask):\n",
    "        _, cls_hs = self.bert(sent_id, attention_mask = mask, return_dict = False)\n",
    "        x = self.fc1(cls_hs)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ace8723",
   "metadata": {},
   "source": [
    "Загрузка модели в GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a90e0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERT_Arch(bert)\n",
    "\n",
    "model = model.to(device)\n",
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995e655c",
   "metadata": {},
   "source": [
    "Нормализация весов в зависимости от соотношения 0/1 в выборке трейна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c9c00ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94444444 1.0625    ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eugene/miniconda3/envs/pytorch/lib/python3.9/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass classes=[0 1], y=11    1\n",
      "15    1\n",
      "0     1\n",
      "18    0\n",
      "13    0\n",
      "12    1\n",
      "20    0\n",
      "7     0\n",
      "21    0\n",
      "16    0\n",
      "5     1\n",
      "4     0\n",
      "19    1\n",
      "9     1\n",
      "8     0\n",
      "3     0\n",
      "1     1\n",
      "Name: target, dtype: int64 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "\n",
    "print(class_weights)\n",
    "\n",
    "weights = torch.tensor(class_weights, dtype = torch.float)\n",
    "weights = weights.to(device)\n",
    "#cross_entropy = nn.CrossEntropyLoss()\n",
    "cross_entropy = nn.NLLLoss(weight=weights)\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d31fa21",
   "metadata": {},
   "source": [
    "Функция для наглядного обучения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82cecfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "    total_preds = []\n",
    "    \n",
    "    for step, batch in tqdm(enumerate(train_dataloader), total = len(train_dataloader)):\n",
    "        batch = [r.to(device) for r in batch]\n",
    "        sent_id,mask,labels = batch\n",
    "        model.zero_grad()\n",
    "        preds = model(sent_id, mask)\n",
    "        loss = cross_entropy(preds, labels)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        preds = preds.detach().cpu().numpy()\n",
    "        total_preds.append(preds)\n",
    "        \n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    total_preds = np.concatenate(total_preds, axis = 0)\n",
    "    \n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309b0200",
   "metadata": {},
   "source": [
    "Функция для тестирования модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0dd27add",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    model.eval()\n",
    "    total_loss, total_accuracy = 0,0\n",
    "    total_preds = []\n",
    "\n",
    "    for step, batch in tqdm(enumerate(test_dataloader), total = len(test_dataloader)):\n",
    "        batch = [t.to(device) for t in batch]\n",
    "        sent_id, mask, labels = batch\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            preds = model(sent_id, mask)\n",
    "            #labels= labels.unsqueeze(1)\n",
    "            loss = cross_entropy(preds, labels)\n",
    "            total_loss = total_loss + loss.item()\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "            total_preds.append(preds)\n",
    "\n",
    "    avg_loss = total_loss / len(test_dataloader)\n",
    "    total_preds = np.concatenate(total_preds, axis = 0)\n",
    "    \n",
    "    \n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8e2934",
   "metadata": {},
   "source": [
    "Обучение новых слоев для задачи классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a84e1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch1 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 13.36it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 20.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.770\n",
      "Test loss: 0.693\n",
      "\n",
      " Epoch2 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 15.92it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 20.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.670\n",
      "Test loss: 0.651\n",
      "\n",
      " Epoch3 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 15.87it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 20.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.624\n",
      "Test loss: 0.604\n",
      "\n",
      " Epoch4 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 15.84it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 20.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.543\n",
      "Test loss: 0.567\n",
      "\n",
      " Epoch5 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 15.85it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 20.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.539\n",
      "Test loss: 0.573\n",
      "\n",
      " Epoch6 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 15.82it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 20.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.530\n",
      "Test loss: 0.624\n",
      "\n",
      " Epoch7 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 16.16it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 20.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.385\n",
      "Test loss: 0.501\n",
      "\n",
      " Epoch8 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 15.86it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 20.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.453\n",
      "Test loss: 0.499\n",
      "\n",
      " Epoch9 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 16.07it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 20.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.376\n",
      "Test loss: 0.521\n",
      "\n",
      " Epoch10 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 16.29it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 21.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.521\n",
      "Test loss: 0.539\n",
      "\n",
      " Epoch11 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 16.35it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 21.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.520\n",
      "Test loss: 1.075\n",
      "\n",
      " Epoch12 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 16.28it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 21.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.498\n",
      "Test loss: 0.390\n",
      "\n",
      " Epoch13 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 16.24it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 20.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.354\n",
      "Test loss: 0.354\n",
      "\n",
      " Epoch14 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 16.26it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 20.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.256\n",
      "Test loss: 0.402\n",
      "\n",
      " Epoch15 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 16.18it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 20.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.237\n",
      "Test loss: 0.300\n",
      "\n",
      " Epoch16 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 16.12it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 21.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.095\n",
      "Test loss: 0.427\n",
      "\n",
      " Epoch17 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 16.35it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 20.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.182\n",
      "Test loss: 0.353\n",
      "\n",
      " Epoch18 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 16.39it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 21.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.202\n",
      "Test loss: 0.357\n",
      "\n",
      " Epoch19 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 16.10it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 20.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.263\n",
      "Test loss: 0.324\n",
      "\n",
      " Epoch20 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 16.29it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 20.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.400\n",
      "Test loss: 0.479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 20.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_test_loss = float('inf')\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('\\n Epoch{:} / {:}'.format(epoch+1, epochs))\n",
    "    \n",
    "    train_loss, _ = train()\n",
    "    test_loss, _ = evaluate()\n",
    "    \n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    print(f'\\nTraining loss: {train_loss:.3f}')\n",
    "    print(f'Test loss: {test_loss:.3f}')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def acc():\n",
    "    model.eval()\n",
    "    total_loss, total_accuracy = 0,0\n",
    "    total_preds = []\n",
    "    total_acc_test = 0\n",
    "\n",
    "    for step, batch in tqdm(enumerate(test_dataloader), total = len(test_dataloader)):\n",
    "        batch = [t.to(device) for t in batch]\n",
    "        sent_id, mask, labels = batch\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            preds = model(sent_id, mask)\n",
    "            #labels= labels.unsqueeze(1)\n",
    "            loss = cross_entropy(preds, labels)\n",
    "            total_loss = total_loss + loss.item()\n",
    "            \n",
    "            test_labels = labels.to(device)\n",
    "            acc = (preds.argmax(dim=1) == test_labels).sum().item()\n",
    "            total_acc_test += acc            \n",
    "            \n",
    "            preds = preds.detach().cpu().numpy()\n",
    "            total_preds.append(preds)\n",
    "            \n",
    "\n",
    "\n",
    "    avg_loss = total_loss / len(test_dataloader)\n",
    "    total_preds = np.concatenate(total_preds, axis = 0)\n",
    "    \n",
    "    print(f'Test Accuracy: {total_acc_test / len(total_preds): .3f}')\n",
    "    return avg_loss, total_preds\n",
    "\n",
    "a,b = acc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d29372d",
   "metadata": {},
   "source": [
    "Загружаем лучшую модель для предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b633e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERT_Arch(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (relu): ReLU()\n",
       "  (fc1): Linear(in_features=768, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (softmax): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'saved_weights.pt'\n",
    "model.load_state_dict(torch.load(path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd959d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bcea520",
   "metadata": {},
   "source": [
    "Предсказываем для сайтов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b2dfec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text\n",
      "0  Изготовление деталей на автоматах продольного ...\n",
      "1  Купить рукав и шланг ГОСТ в Москве недорого – ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 31.33it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Изготовление деталей на автоматах продольного ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Купить рукав и шланг ГОСТ в Москве недорого – ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  Изготовление деталей на автоматах продольного ...       1\n",
       "1  Купить рукав и шланг ГОСТ в Москве недорого – ...       1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Для демо читаем сохраненные файлы с диска, в реальном ПО можно подать просто html\n",
    "\n",
    "sites = ['dataset/0.html', 'dataset/16.html']\n",
    "texts = []\n",
    "\n",
    "for s in sites:\n",
    "    with open(s) as f:\n",
    "        lines = f.read()\n",
    "        lines = lines.rstrip().replace(' - ','').replace(' | ', '')\n",
    "        clean_text = ' '.join(BeautifulSoup(lines, \"html.parser\").stripped_strings)\n",
    "        texts.append([clean_text])\n",
    "\n",
    "pred_df = pd.DataFrame(texts, columns = ['text'])\n",
    "print(pred_df)\n",
    "\n",
    "def predict(df):\n",
    "    \"\"\"\n",
    "    Берем из pandas таблицы столбец text, в котором текст сайта\n",
    "    добавляев в pandas таблицу столбец target, в котором 0 - маркетплейс, 1 - сайт поставщика\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    batch_size = 1\n",
    "    tokens_predict = tokenizer.batch_encode_plus(\n",
    "        df['text'].values,\n",
    "        max_length = 500,\n",
    "        padding = 'max_length',\n",
    "        truncation = True\n",
    "    )\n",
    "    \n",
    "    total_preds = []\n",
    "    \n",
    "    predict_seq = torch.tensor(tokens_predict['input_ids'])\n",
    "    predict_mask = torch.tensor(tokens_predict['attention_mask'])\n",
    "    predict_data =  TensorDataset(predict_seq, predict_mask)\n",
    "    predict_sampler = SequentialSampler(predict_data)\n",
    "    predict_dataloader = DataLoader(predict_data, sampler = predict_sampler, batch_size = batch_size)\n",
    "    \n",
    "    \n",
    "    for step, batch in tqdm(enumerate(predict_dataloader), total = len(predict_dataloader)):\n",
    "        batch = [t.to(device) for t in batch]\n",
    "        sent_id, mask = batch\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            preds = model(sent_id, mask)\n",
    "            preds = preds.detach().cpu().numpy()    \n",
    "            preds = np.argmax(preds)\n",
    "            total_preds.append(preds)\n",
    "    df['target'] = total_preds\n",
    "    return df\n",
    "\n",
    "\n",
    "pred_df = predict(pred_df)\n",
    "display(pred_df)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689759b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01004916",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
