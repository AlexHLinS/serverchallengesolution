{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c97323ae",
   "metadata": {},
   "source": [
    "# Классификация текста с помощью трансформера BERT\n",
    "\n",
    "Оригинальная идея подчерпнута отсюда https://www.kaggle.com/c/learn-ai-bbc и отсюда https://habr.com/ru/post/655517/\n",
    "\n",
    "\n",
    "### Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11712e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "device = torch.device('cuda')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8250e23",
   "metadata": {},
   "source": [
    "### Чтение нашего датасета, состоящего из html и лейблов в txt файле\n",
    "\n",
    "В файле две строки\n",
    "\n",
    "Первая:\n",
    " - Label 0 - Маркет\n",
    " - Label 1 - Сайт\n",
    " - Label 2 - Мусор\n",
    "\n",
    "\n",
    "Вторая: \n",
    " - Label 0 - Производитель\n",
    " - Label 1 - Перекуп\n",
    "\n",
    "Сейчас работаем по **второй**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6e6face",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Рукав газовый ( шланг) купить в Москве со скид...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>КонтактыООО«Торговый дом«Снабжение» Обратная с...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Крепеж STRONG КАТАЛОГ О НАС ДОСТАВКА И ОПЛАТА ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Главная страница Торговый дом РТИ (Санкт-Петер...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Сварочные инверторы TIG AC/DC купить в Москве....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Шайба плоская цена, купить в России от ТрубТех...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Метизы цена, купить в РоссииМеталлЭнергоХолдин...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gesacофициальный дистрибьютор в России НАШИ ПР...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>заказать шплинт,шайбу,гровер О нас Новости Кон...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Оборудование щеточное, Навесное оборудование д...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  Рукав газовый ( шланг) купить в Москве со скид...       1\n",
       "1  КонтактыООО«Торговый дом«Снабжение» Обратная с...       0\n",
       "2  Крепеж STRONG КАТАЛОГ О НАС ДОСТАВКА И ОПЛАТА ...       1\n",
       "3  Главная страница Торговый дом РТИ (Санкт-Петер...       0\n",
       "4  Сварочные инверторы TIG AC/DC купить в Москве....       1\n",
       "5  Шайба плоская цена, купить в России от ТрубТех...       1\n",
       "6  Метизы цена, купить в РоссииМеталлЭнергоХолдин...       0\n",
       "7  Gesacофициальный дистрибьютор в России НАШИ ПР...       1\n",
       "8  заказать шплинт,шайбу,гровер О нас Новости Кон...       0\n",
       "9  Оборудование щеточное, Навесное оборудование д...       1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "indir = 'dataset2'\n",
    "indir = os.path.abspath(indir)\n",
    "\n",
    "sites = [x for x in os.listdir(indir) if x.endswith('.txt')]\n",
    "\n",
    "pairs = []\n",
    "\n",
    "for pair in sites:\n",
    "    site = os.path.splitext(pair)[0] + '.html'\n",
    "    \n",
    "\n",
    "    with open(os.path.join(indir, site)) as f:\n",
    "        lines = f.read().rstrip().replace(' - ','').replace(' | ', '')\n",
    "        clean_text = ' '.join(BeautifulSoup(lines, \"html.parser\").stripped_strings)\n",
    "        \n",
    "    with open(os.path.join(indir, pair)) as f:\n",
    "        lines = f.readlines()\n",
    "        label = int(lines[1])\n",
    "        \n",
    "    pairs.append([clean_text, label])\n",
    "\n",
    "#print(pairs)\n",
    "\n",
    "df = pd.DataFrame(pairs, columns = ['text', 'target'])\n",
    "\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581e4518",
   "metadata": {},
   "source": [
    "Загрузка претренированной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "617475e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = AutoModel.from_pretrained(\"DeepPavlov/rubert-base-cased-sentence\")\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased-sentence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37ac14f",
   "metadata": {},
   "source": [
    "Разбиение выборок на текст и таргет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0f92c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text'].astype('str')\n",
    "y = df['target'].astype(int)\n",
    "\n",
    "X_train, y_train = X,y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf29547a",
   "metadata": {},
   "source": [
    "График длин текстов. Он поможет определить оптимальную длину последовательности токенов, чтобы избежать разреженных векторов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bf9604f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_len = [len(str(i).split()) for i in X_train]\n",
    "pd.Series(seq_len).hist(bins = 100, range =(0,5000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e20c44",
   "metadata": {},
   "source": [
    "Токенизация текста\n",
    "Берем длину 500 (эта реализация BERT не дает сделать больше 512 к сожалению)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "265a4d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_len = 500\n",
    "\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    X_train.values,\n",
    "    max_length = token_len,\n",
    "    padding = 'max_length',\n",
    "    truncation = True\n",
    ")\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    X_test.values,\n",
    "    max_length = token_len,\n",
    "    padding = 'max_length',\n",
    "    truncation = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c760e2f9",
   "metadata": {},
   "source": [
    "Создание датасета для обучения из токенов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82a5a775",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "\n",
    "\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(y_train.values)\n",
    "\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(y_test.values)\n",
    "\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler = train_sampler, batch_size = batch_size)\n",
    "\n",
    "test_data =  TensorDataset(test_seq, test_mask, test_y)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler = test_sampler, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "101a0acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(test_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9152fb59",
   "metadata": {},
   "source": [
    "Вместо обучения всего BERT добавим слой для классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a0d6123",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in bert.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "class BERT_Arch(nn.Module):\n",
    "    \n",
    "    def __init__(self, bert):\n",
    "        super(BERT_Arch, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(768,512)\n",
    "        self.fc2 = nn.Linear(512,2)\n",
    "        self.softmax = nn.LogSoftmax(dim = 1)\n",
    "    \n",
    "    def forward(self, sent_id, mask):\n",
    "        _, cls_hs = self.bert(sent_id, attention_mask = mask, return_dict = False)\n",
    "        x = self.fc1(cls_hs)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3204c78d",
   "metadata": {},
   "source": [
    "Загрузка модели в GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9370dd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERT_Arch(bert)\n",
    "\n",
    "model = model.to(device)\n",
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566931da",
   "metadata": {},
   "source": [
    "Нормализация весов в зависимости от соотношения 0/1 в выборке трейна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45ce937d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.16666667 0.875     ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eugene/miniconda3/envs/pytorch/lib/python3.9/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass classes=[0 1], y=2    1\n",
      "6    0\n",
      "7    1\n",
      "0    1\n",
      "9    1\n",
      "3    0\n",
      "1    0\n",
      "Name: target, dtype: int64 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "\n",
    "print(class_weights)\n",
    "\n",
    "weights = torch.tensor(class_weights, dtype = torch.float)\n",
    "weights = weights.to(device)\n",
    "#cross_entropy = nn.CrossEntropyLoss()\n",
    "cross_entropy = nn.NLLLoss(weight=weights)\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ba0765",
   "metadata": {},
   "source": [
    "Функция для наглядного обучения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53466c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "    total_preds = []\n",
    "    \n",
    "    for step, batch in tqdm(enumerate(train_dataloader), total = len(train_dataloader)):\n",
    "        batch = [r.to(device) for r in batch]\n",
    "        sent_id,mask,labels = batch\n",
    "        model.zero_grad()\n",
    "        preds = model(sent_id, mask)\n",
    "        loss = cross_entropy(preds, labels)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        preds = preds.detach().cpu().numpy()\n",
    "        total_preds.append(preds)\n",
    "        \n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    total_preds = np.concatenate(total_preds, axis = 0)\n",
    "    \n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e347c40",
   "metadata": {},
   "source": [
    "Функция для тестирования модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae63605d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    model.eval()\n",
    "    total_loss, total_accuracy = 0,0\n",
    "    total_preds = []\n",
    "\n",
    "    for step, batch in tqdm(enumerate(test_dataloader), total = len(test_dataloader)):\n",
    "        batch = [t.to(device) for t in batch]\n",
    "        sent_id, mask, labels = batch\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            preds = model(sent_id, mask)\n",
    "            #labels= labels.unsqueeze(1)\n",
    "            loss = cross_entropy(preds, labels)\n",
    "            total_loss = total_loss + loss.item()\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "            total_preds.append(preds)\n",
    "\n",
    "    avg_loss = total_loss / len(test_dataloader)\n",
    "    total_preds = np.concatenate(total_preds, axis = 0)\n",
    "    \n",
    "    \n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07f5842",
   "metadata": {},
   "source": [
    "Обучение новых слоев для задачи классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28d9fae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch1 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 10.52it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 22.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 1.020\n",
      "Test loss: 0.778\n",
      "\n",
      " Epoch2 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 17.36it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 23.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.794\n",
      "Test loss: 0.619\n",
      "\n",
      " Epoch3 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 16.85it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 22.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.686\n",
      "Test loss: 0.723\n",
      "\n",
      " Epoch4 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 16.65it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 22.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.705\n",
      "Test loss: 0.742\n",
      "\n",
      " Epoch5 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 16.83it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 22.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.599\n",
      "Test loss: 0.658\n",
      "\n",
      " Epoch6 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 16.75it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 22.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.654\n",
      "Test loss: 0.609\n",
      "\n",
      " Epoch7 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 16.90it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 22.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.615\n",
      "Test loss: 0.645\n",
      "\n",
      " Epoch8 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 16.81it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 22.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.547\n",
      "Test loss: 0.653\n",
      "\n",
      " Epoch9 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 16.71it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 22.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.574\n",
      "Test loss: 0.684\n",
      "\n",
      " Epoch10 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 16.69it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 22.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.501\n",
      "Test loss: 0.683\n",
      "\n",
      " Epoch11 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 16.96it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 22.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.495\n",
      "Test loss: 0.647\n",
      "\n",
      " Epoch12 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 16.78it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 22.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.421\n",
      "Test loss: 0.604\n",
      "\n",
      " Epoch13 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 17.24it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 23.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.434\n",
      "Test loss: 0.563\n",
      "\n",
      " Epoch14 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 17.35it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 23.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.480\n",
      "Test loss: 0.476\n",
      "\n",
      " Epoch15 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 16.96it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 22.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.334\n",
      "Test loss: 0.479\n",
      "\n",
      " Epoch16 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 16.71it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 22.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.372\n",
      "Test loss: 0.514\n",
      "\n",
      " Epoch17 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 16.69it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 22.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.301\n",
      "Test loss: 0.497\n",
      "\n",
      " Epoch18 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 16.73it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 22.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.314\n",
      "Test loss: 0.559\n",
      "\n",
      " Epoch19 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 16.83it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 22.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.241\n",
      "Test loss: 0.741\n",
      "\n",
      " Epoch20 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 16.73it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 22.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.174\n",
      "Test loss: 0.644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 22.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_test_loss = float('inf')\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('\\n Epoch{:} / {:}'.format(epoch+1, epochs))\n",
    "    \n",
    "    train_loss, _ = train()\n",
    "    test_loss, _ = evaluate()\n",
    "    \n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    print(f'\\nTraining loss: {train_loss:.3f}')\n",
    "    print(f'Test loss: {test_loss:.3f}')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def acc():\n",
    "    model.eval()\n",
    "    total_loss, total_accuracy = 0,0\n",
    "    total_preds = []\n",
    "    total_acc_test = 0\n",
    "\n",
    "    for step, batch in tqdm(enumerate(test_dataloader), total = len(test_dataloader)):\n",
    "        batch = [t.to(device) for t in batch]\n",
    "        sent_id, mask, labels = batch\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            preds = model(sent_id, mask)\n",
    "            #labels= labels.unsqueeze(1)\n",
    "            loss = cross_entropy(preds, labels)\n",
    "            total_loss = total_loss + loss.item()\n",
    "            \n",
    "            test_labels = labels.to(device)\n",
    "            acc = (preds.argmax(dim=1) == test_labels).sum().item()\n",
    "            total_acc_test += acc            \n",
    "            \n",
    "            preds = preds.detach().cpu().numpy()\n",
    "            total_preds.append(preds)\n",
    "            \n",
    "\n",
    "\n",
    "    avg_loss = total_loss / len(test_dataloader)\n",
    "    total_preds = np.concatenate(total_preds, axis = 0)\n",
    "    \n",
    "    print(f'Test Accuracy: {total_acc_test / len(total_preds): .3f}')\n",
    "    return avg_loss, total_preds\n",
    "\n",
    "a,b = acc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c42ea0",
   "metadata": {},
   "source": [
    "Загружаем лучшую модель для предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fea88dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERT_Arch(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (relu): ReLU()\n",
       "  (fc1): Linear(in_features=768, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (softmax): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'saved_weights.pt'\n",
    "model.load_state_dict(torch.load(path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8400213",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "949c07f9",
   "metadata": {},
   "source": [
    "Предсказываем для сайтов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68b00920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>заказать шплинт,шайбу,гровер О нас Новости Кон...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Главная страница Торговый дом РТИ (Санкт-Петер...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Рукав газовый ( шланг) купить в Москве со скид...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Оборудование щеточное, Навесное оборудование д...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Крепеж STRONG КАТАЛОГ О НАС ДОСТАВКА И ОПЛАТА ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  заказать шплинт,шайбу,гровер О нас Новости Кон...\n",
       "1  Главная страница Торговый дом РТИ (Санкт-Петер...\n",
       "2  Рукав газовый ( шланг) купить в Москве со скид...\n",
       "3  Оборудование щеточное, Навесное оборудование д...\n",
       "4  Крепеж STRONG КАТАЛОГ О НАС ДОСТАВКА И ОПЛАТА ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 32.70it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>заказать шплинт,шайбу,гровер О нас Новости Кон...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Главная страница Торговый дом РТИ (Санкт-Петер...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Рукав газовый ( шланг) купить в Москве со скид...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Оборудование щеточное, Навесное оборудование д...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Крепеж STRONG КАТАЛОГ О НАС ДОСТАВКА И ОПЛАТА ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  заказать шплинт,шайбу,гровер О нас Новости Кон...       1\n",
       "1  Главная страница Торговый дом РТИ (Санкт-Петер...       0\n",
       "2  Рукав газовый ( шланг) купить в Москве со скид...       1\n",
       "3  Оборудование щеточное, Навесное оборудование д...       1\n",
       "4  Крепеж STRONG КАТАЛОГ О НАС ДОСТАВКА И ОПЛАТА ...       1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Для демо читаем сохраненные файлы с диска, в реальном ПО можно подать просто html\n",
    "\n",
    "sites = ['dataset2/a8.html', 'dataset2/a9.html', 'dataset2/a3.html', 'dataset2/a4.html', 'dataset2/a7.html']\n",
    "texts = []\n",
    "\n",
    "for s in sites:\n",
    "    with open(s) as f:\n",
    "        lines = f.read()\n",
    "        lines = lines.rstrip().replace(' - ','').replace(' | ', '')\n",
    "        clean_text = ' '.join(BeautifulSoup(lines, \"html.parser\").stripped_strings)\n",
    "        texts.append([clean_text])\n",
    "\n",
    "pred_df = pd.DataFrame(texts, columns = ['text'])\n",
    "display(pred_df)\n",
    "\n",
    "def predict(df):\n",
    "    \"\"\"\n",
    "    Берем из pandas таблицы столбец text, в котором текст сайта\n",
    "    добавляев в pandas таблицу столбец target, в котором 0 - маркетплейс, 1 - сайт поставщика\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    batch_size = 1\n",
    "    tokens_predict = tokenizer.batch_encode_plus(\n",
    "        df['text'].values,\n",
    "        max_length = 500,\n",
    "        padding = 'max_length',\n",
    "        truncation = True\n",
    "    )\n",
    "    \n",
    "    total_preds = []\n",
    "    \n",
    "    predict_seq = torch.tensor(tokens_predict['input_ids'])\n",
    "    predict_mask = torch.tensor(tokens_predict['attention_mask'])\n",
    "    predict_data =  TensorDataset(predict_seq, predict_mask)\n",
    "    predict_sampler = SequentialSampler(predict_data)\n",
    "    predict_dataloader = DataLoader(predict_data, sampler = predict_sampler, batch_size = batch_size)\n",
    "    \n",
    "    \n",
    "    for step, batch in tqdm(enumerate(predict_dataloader), total = len(predict_dataloader)):\n",
    "        batch = [t.to(device) for t in batch]\n",
    "        sent_id, mask = batch\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            preds = model(sent_id, mask)\n",
    "            preds = preds.detach().cpu().numpy()    \n",
    "            preds = np.argmax(preds)\n",
    "            total_preds.append(preds)\n",
    "    df['target'] = total_preds\n",
    "    return df\n",
    "\n",
    "\n",
    "pred_df = predict(pred_df)\n",
    "display(pred_df)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2135360",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979b6c96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
